== Kubernetes custom resource options
The cluster can be configured via a YAML file. This custom resource specifies the amount of replicas for each role group or role specific configuration like port definitions etc.

[source,yaml]
----
apiVersion: spark.stackable.tech/v1alpha1
kind: SparkCluster
metadata:
  name: simple
spec:
  version: "3.0.1"
  config:
    logDir: /stackable/data/log
    enableMonitoring: true
  masters:
    roleGroups:
      default:
        selector:
          matchLabels:
            kubernetes.io/os: linux
        replicas: 1
        config:
          masterPort: 7078
          masterWebUiPort: 8081
        configOverrides:
          spark-defaults.conf:
            spark.driver.memory: 2g
          spark-env.sh:
            MASTER_ENV_VAR: test_value
  workers:
    roleGroups:
      2core2g:
        selector:
          matchLabels:
            kubernetes.io/os: linux
        replicas: 1
        config:
          cores: 2
          memory: "2g"
          workerPort: 3031
          workerWebUiPort: 8083
        configOverrides:
          spark-defaults.conf:
            spark.driver.memory: 2g
          spark-env.sh:
            WORKER_ENV_VAR: test_value
  historyServers:
    roleGroups:
      default:
        selector:
          matchLabels:
            kubernetes.io/os: linux
        replicas: 1
        config:
          historyWebUiPort: 18081
        configOverrides:
          spark-defaults.conf:
            history.override: dummy_value
          spark-env.sh:
            HISTORY_ENV_VAR: test_value
----

== Configuration Overrides
Apache Spark runtime configuration is stored in a file named spark-defaults.conf. The configOverrides block allows you to add custom parameters to this file. A Full list of the available configuration options can be found in the official Apache Spark documentation at https://spark.apache.org/docs/latest/configuration.html.

Overrides consist of a key, which must match the property name in the configuration file and a value. This allows arbitrary configuration properties to be added to Spark. In the example above a dummy property spark.driver.memory is being explicitly set to '2g' for both the master and worker roles, overriding the default value.

== Configuration Properties
Below is a list of the configuration properties exposed by the Stackable Spark operator. These properties can be added to the golbal config block or the role config block of a Spark cluster CRD.

[cols="2,2,2,2,1"]
|===
| config-spec Property | Scope  | Description | Default Value | Location

| enableMonitoring
| Cluster
| All pods will be annotated for metric scraping. Metrics are retrieved from Spark's built-in Prometheus Servlet.
| false
|

| logDir
| Cluster
|
|
|spark-defaults.conf

| maxPortRetries
| Cluster
|
|
|

| secret
| Cluster
| Shared secret for Spark RPC authentication
|
|spark-defaults.conf

|historyWebUiPort|historyServers|Port for Spark history server web UI||
|storePath|historyServers|Location to store Spark job history||spark-defaults.conf

|masterPort|masters|Port for Spark master|7078|
|masterWebUiPort|masters|Port for Spark master web UI|8081|

|cores|workers|Number of cores available on worker node for Spark jobs||
|memory|workers|Amount of memory avilable on worker node for Spark jobs||
|workerPort|workers|Port for Spark worker|3031|
|workerWebUiPort|workers|Port for Spark worker web UI|8083|


|===